{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "            label  player_0_w  player_0_l  player_0_co_w  player_0_co_l  \\\ngame_id                                                                   \n548809662       0         216         181            145             91   \n4484824702      0         541         503             27             28   \n548810655       1         155         146             20              6   \n6140028214      1         686         645             43             41   \n1351099000      1          31          14             23              8   \n\n            player_0_ct_wr  player_1_w  player_1_l  player_1_co_w  \\\ngame_id                                                             \n548809662           0.5354         174         147              8   \n4484824702          0.5161         160         111              0   \n548810655           0.4879          55          46              0   \n6140028214          0.5082         368         281             17   \n1351099000          0.5043          38          12              2   \n\n            player_1_co_l  ...  player_8_w  player_8_l  player_8_co_w  \\\ngame_id                    ...                                          \n548809662               3  ...         297         284              1   \n4484824702              0  ...         269         202              9   \n548810655               0  ...         186         144             22   \n6140028214             11  ...         234         198             25   \n1351099000              0  ...          17           6              8   \n\n            player_8_co_l  player_8_ct_wr  player_9_w  player_9_l  \\\ngame_id                                                             \n548809662               0          0.5003         941         930   \n4484824702              3          0.4971         988         954   \n548810655              23          0.5088          55          45   \n6140028214             32          0.5197        2090        2035   \n1351099000              3          0.5148         125         103   \n\n            player_9_co_w  player_9_co_l  player_9_ct_wr  \ngame_id                                                   \n548809662              43             35          0.5093  \n4484824702             65             78          0.4948  \n548810655               0              1          0.5229  \n6140028214            390            340          0.5306  \n1351099000              0              0          0.4933  \n\n[5 rows x 51 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>player_0_w</th>\n      <th>player_0_l</th>\n      <th>player_0_co_w</th>\n      <th>player_0_co_l</th>\n      <th>player_0_ct_wr</th>\n      <th>player_1_w</th>\n      <th>player_1_l</th>\n      <th>player_1_co_w</th>\n      <th>player_1_co_l</th>\n      <th>...</th>\n      <th>player_8_w</th>\n      <th>player_8_l</th>\n      <th>player_8_co_w</th>\n      <th>player_8_co_l</th>\n      <th>player_8_ct_wr</th>\n      <th>player_9_w</th>\n      <th>player_9_l</th>\n      <th>player_9_co_w</th>\n      <th>player_9_co_l</th>\n      <th>player_9_ct_wr</th>\n    </tr>\n    <tr>\n      <th>game_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>548809662</td>\n      <td>0</td>\n      <td>216</td>\n      <td>181</td>\n      <td>145</td>\n      <td>91</td>\n      <td>0.5354</td>\n      <td>174</td>\n      <td>147</td>\n      <td>8</td>\n      <td>3</td>\n      <td>...</td>\n      <td>297</td>\n      <td>284</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.5003</td>\n      <td>941</td>\n      <td>930</td>\n      <td>43</td>\n      <td>35</td>\n      <td>0.5093</td>\n    </tr>\n    <tr>\n      <td>4484824702</td>\n      <td>0</td>\n      <td>541</td>\n      <td>503</td>\n      <td>27</td>\n      <td>28</td>\n      <td>0.5161</td>\n      <td>160</td>\n      <td>111</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>269</td>\n      <td>202</td>\n      <td>9</td>\n      <td>3</td>\n      <td>0.4971</td>\n      <td>988</td>\n      <td>954</td>\n      <td>65</td>\n      <td>78</td>\n      <td>0.4948</td>\n    </tr>\n    <tr>\n      <td>548810655</td>\n      <td>1</td>\n      <td>155</td>\n      <td>146</td>\n      <td>20</td>\n      <td>6</td>\n      <td>0.4879</td>\n      <td>55</td>\n      <td>46</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>186</td>\n      <td>144</td>\n      <td>22</td>\n      <td>23</td>\n      <td>0.5088</td>\n      <td>55</td>\n      <td>45</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.5229</td>\n    </tr>\n    <tr>\n      <td>6140028214</td>\n      <td>1</td>\n      <td>686</td>\n      <td>645</td>\n      <td>43</td>\n      <td>41</td>\n      <td>0.5082</td>\n      <td>368</td>\n      <td>281</td>\n      <td>17</td>\n      <td>11</td>\n      <td>...</td>\n      <td>234</td>\n      <td>198</td>\n      <td>25</td>\n      <td>32</td>\n      <td>0.5197</td>\n      <td>2090</td>\n      <td>2035</td>\n      <td>390</td>\n      <td>340</td>\n      <td>0.5306</td>\n    </tr>\n    <tr>\n      <td>1351099000</td>\n      <td>1</td>\n      <td>31</td>\n      <td>14</td>\n      <td>23</td>\n      <td>8</td>\n      <td>0.5043</td>\n      <td>38</td>\n      <td>12</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>17</td>\n      <td>6</td>\n      <td>8</td>\n      <td>3</td>\n      <td>0.5148</td>\n      <td>125</td>\n      <td>103</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.4933</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 51 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from plug_mongo import get_entries\n",
    "df = pd.DataFrame(get_entries()).drop([\"_id\", \"timestamp\"], axis=1).set_index(\"game_id\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "game_id\n548809662     0.543860\n4484824702    0.518164\n548810655     0.514851\n6140028214    0.515379\n1351099000    0.680851\nName: player_0_wr, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_one(column):\n",
    "\treturn df[column].apply(lambda x: x+1)\n",
    "\n",
    "def get_winrate(column):\n",
    "\twin = add_one(column+'_w')\n",
    "\tlos = add_one(column+'_l')\n",
    "\treturn (win / (win + los)).rename(column+\"_wr\")\n",
    "\n",
    "get_winrate('player_0').head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "            label  player_0_w  player_0_l  player_0_co_w  player_0_co_l  \\\ngame_id                                                                   \n548809662       0         216         181            145             91   \n4484824702      0         541         503             27             28   \n548810655       1         155         146             20              6   \n6140028214      1         686         645             43             41   \n1351099000      1          31          14             23              8   \n\n            player_0_ct_wr  player_1_w  player_1_l  player_1_co_w  \\\ngame_id                                                             \n548809662           0.5354         174         147              8   \n4484824702          0.5161         160         111              0   \n548810655           0.4879          55          46              0   \n6140028214          0.5082         368         281             17   \n1351099000          0.5043          38          12              2   \n\n            player_1_co_l  ...  player_0_co_wr  player_1_co_wr  \\\ngame_id                    ...                                   \n548809662               3  ...        0.613445        0.692308   \n4484824702              0  ...        0.491228        0.500000   \n548810655               0  ...        0.750000        0.500000   \n6140028214             11  ...        0.511628        0.600000   \n1351099000              0  ...        0.727273        0.750000   \n\n            player_2_co_wr  player_3_co_wr  player_4_co_wr  player_5_co_wr  \\\ngame_id                                                                      \n548809662         0.789474        0.482759        0.700000        0.500000   \n4484824702        0.533537        0.727273        0.545763        0.428571   \n548810655         0.500000        0.285714        0.333333        0.500000   \n6140028214        0.764706        0.625000        0.800000        0.642857   \n1351099000        0.428571        0.500000        0.666667        0.531469   \n\n            player_6_co_wr  player_7_co_wr  player_8_co_wr  player_9_co_wr  \ngame_id                                                                     \n548809662         0.584211        0.666667        0.666667        0.550000  \n4484824702        0.666667        0.549020        0.714286        0.455172  \n548810655         0.500000        0.500000        0.489362        0.333333  \n6140028214        0.527538        0.606383        0.440678        0.534153  \n1351099000        0.666667        0.500000        0.692308        0.500000  \n\n[5 rows x 71 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>player_0_w</th>\n      <th>player_0_l</th>\n      <th>player_0_co_w</th>\n      <th>player_0_co_l</th>\n      <th>player_0_ct_wr</th>\n      <th>player_1_w</th>\n      <th>player_1_l</th>\n      <th>player_1_co_w</th>\n      <th>player_1_co_l</th>\n      <th>...</th>\n      <th>player_0_co_wr</th>\n      <th>player_1_co_wr</th>\n      <th>player_2_co_wr</th>\n      <th>player_3_co_wr</th>\n      <th>player_4_co_wr</th>\n      <th>player_5_co_wr</th>\n      <th>player_6_co_wr</th>\n      <th>player_7_co_wr</th>\n      <th>player_8_co_wr</th>\n      <th>player_9_co_wr</th>\n    </tr>\n    <tr>\n      <th>game_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>548809662</td>\n      <td>0</td>\n      <td>216</td>\n      <td>181</td>\n      <td>145</td>\n      <td>91</td>\n      <td>0.5354</td>\n      <td>174</td>\n      <td>147</td>\n      <td>8</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0.613445</td>\n      <td>0.692308</td>\n      <td>0.789474</td>\n      <td>0.482759</td>\n      <td>0.700000</td>\n      <td>0.500000</td>\n      <td>0.584211</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.550000</td>\n    </tr>\n    <tr>\n      <td>4484824702</td>\n      <td>0</td>\n      <td>541</td>\n      <td>503</td>\n      <td>27</td>\n      <td>28</td>\n      <td>0.5161</td>\n      <td>160</td>\n      <td>111</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.491228</td>\n      <td>0.500000</td>\n      <td>0.533537</td>\n      <td>0.727273</td>\n      <td>0.545763</td>\n      <td>0.428571</td>\n      <td>0.666667</td>\n      <td>0.549020</td>\n      <td>0.714286</td>\n      <td>0.455172</td>\n    </tr>\n    <tr>\n      <td>548810655</td>\n      <td>1</td>\n      <td>155</td>\n      <td>146</td>\n      <td>20</td>\n      <td>6</td>\n      <td>0.4879</td>\n      <td>55</td>\n      <td>46</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.750000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.285714</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.489362</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <td>6140028214</td>\n      <td>1</td>\n      <td>686</td>\n      <td>645</td>\n      <td>43</td>\n      <td>41</td>\n      <td>0.5082</td>\n      <td>368</td>\n      <td>281</td>\n      <td>17</td>\n      <td>11</td>\n      <td>...</td>\n      <td>0.511628</td>\n      <td>0.600000</td>\n      <td>0.764706</td>\n      <td>0.625000</td>\n      <td>0.800000</td>\n      <td>0.642857</td>\n      <td>0.527538</td>\n      <td>0.606383</td>\n      <td>0.440678</td>\n      <td>0.534153</td>\n    </tr>\n    <tr>\n      <td>1351099000</td>\n      <td>1</td>\n      <td>31</td>\n      <td>14</td>\n      <td>23</td>\n      <td>8</td>\n      <td>0.5043</td>\n      <td>38</td>\n      <td>12</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.727273</td>\n      <td>0.750000</td>\n      <td>0.428571</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.531469</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>0.692308</td>\n      <td>0.500000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 71 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [df]\n",
    "result.extend([get_winrate(f\"player_{x}\") for x in range(10)])\n",
    "result.extend([get_winrate(f\"player_{x}_co\") for x in range(10)])\n",
    "df_winrates = pd.concat(result, axis=1)\n",
    "df_winrates.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "            label  player_0_w  player_0_l  player_0_co_w  player_0_co_l  \\\ngame_id                                                                   \n3252704800      0         419         427             29             15   \n4488699054      0         359         316            331            280   \n3254899506      0         201         221              6              8   \n6145685471      0         366         316             19             14   \n1237727628      0         104          85             28             14   \n\n            player_0_ct_wr  player_1_w  player_1_l  player_1_co_w  \\\ngame_id                                                             \n3252704800          0.5127          32          24              2   \n4488699054          0.5298         134         101              2   \n3254899506          0.4836         266         226              1   \n6145685471          0.4927         554         514              8   \n1237727628          0.5012         152         154              3   \n\n            player_1_co_l  ...  player_0_co_wr  player_1_co_wr  \\\ngame_id                    ...                                   \n3252704800              0  ...        0.652174        0.750000   \n4488699054              1  ...        0.541599        0.600000   \n3254899506              1  ...        0.437500        0.500000   \n6145685471             15  ...        0.571429        0.360000   \n1237727628              4  ...        0.659091        0.444444   \n\n            player_2_co_wr  player_3_co_wr  player_4_co_wr  player_5_co_wr  \\\ngame_id                                                                      \n3252704800        0.666667        0.651163        0.750000        0.647059   \n4488699054        0.833333        0.444444        0.500000        0.800000   \n3254899506        0.571429        0.636364        0.750000        0.571429   \n6145685471        0.618182        0.600000        0.666667        0.488372   \n1237727628        0.600000        0.421053        0.567901        0.857143   \n\n            player_6_co_wr  player_7_co_wr  player_8_co_wr  player_9_co_wr  \ngame_id                                                                     \n3252704800        0.594203        0.655738        0.500000        0.500000  \n4488699054        0.513514        0.521739        0.560606        0.454545  \n3254899506        0.583333        0.697674        0.333333        0.500000  \n6145685471        0.429630        0.629213        0.600000        0.555556  \n1237727628        0.600000        0.333333        0.625000        0.384615  \n\n[5 rows x 71 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>player_0_w</th>\n      <th>player_0_l</th>\n      <th>player_0_co_w</th>\n      <th>player_0_co_l</th>\n      <th>player_0_ct_wr</th>\n      <th>player_1_w</th>\n      <th>player_1_l</th>\n      <th>player_1_co_w</th>\n      <th>player_1_co_l</th>\n      <th>...</th>\n      <th>player_0_co_wr</th>\n      <th>player_1_co_wr</th>\n      <th>player_2_co_wr</th>\n      <th>player_3_co_wr</th>\n      <th>player_4_co_wr</th>\n      <th>player_5_co_wr</th>\n      <th>player_6_co_wr</th>\n      <th>player_7_co_wr</th>\n      <th>player_8_co_wr</th>\n      <th>player_9_co_wr</th>\n    </tr>\n    <tr>\n      <th>game_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>3252704800</td>\n      <td>0</td>\n      <td>419</td>\n      <td>427</td>\n      <td>29</td>\n      <td>15</td>\n      <td>0.5127</td>\n      <td>32</td>\n      <td>24</td>\n      <td>2</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.652174</td>\n      <td>0.750000</td>\n      <td>0.666667</td>\n      <td>0.651163</td>\n      <td>0.750000</td>\n      <td>0.647059</td>\n      <td>0.594203</td>\n      <td>0.655738</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>4488699054</td>\n      <td>0</td>\n      <td>359</td>\n      <td>316</td>\n      <td>331</td>\n      <td>280</td>\n      <td>0.5298</td>\n      <td>134</td>\n      <td>101</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.541599</td>\n      <td>0.600000</td>\n      <td>0.833333</td>\n      <td>0.444444</td>\n      <td>0.500000</td>\n      <td>0.800000</td>\n      <td>0.513514</td>\n      <td>0.521739</td>\n      <td>0.560606</td>\n      <td>0.454545</td>\n    </tr>\n    <tr>\n      <td>3254899506</td>\n      <td>0</td>\n      <td>201</td>\n      <td>221</td>\n      <td>6</td>\n      <td>8</td>\n      <td>0.4836</td>\n      <td>266</td>\n      <td>226</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.437500</td>\n      <td>0.500000</td>\n      <td>0.571429</td>\n      <td>0.636364</td>\n      <td>0.750000</td>\n      <td>0.571429</td>\n      <td>0.583333</td>\n      <td>0.697674</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>6145685471</td>\n      <td>0</td>\n      <td>366</td>\n      <td>316</td>\n      <td>19</td>\n      <td>14</td>\n      <td>0.4927</td>\n      <td>554</td>\n      <td>514</td>\n      <td>8</td>\n      <td>15</td>\n      <td>...</td>\n      <td>0.571429</td>\n      <td>0.360000</td>\n      <td>0.618182</td>\n      <td>0.600000</td>\n      <td>0.666667</td>\n      <td>0.488372</td>\n      <td>0.429630</td>\n      <td>0.629213</td>\n      <td>0.600000</td>\n      <td>0.555556</td>\n    </tr>\n    <tr>\n      <td>1237727628</td>\n      <td>0</td>\n      <td>104</td>\n      <td>85</td>\n      <td>28</td>\n      <td>14</td>\n      <td>0.5012</td>\n      <td>152</td>\n      <td>154</td>\n      <td>3</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0.659091</td>\n      <td>0.444444</td>\n      <td>0.600000</td>\n      <td>0.421053</td>\n      <td>0.567901</td>\n      <td>0.857143</td>\n      <td>0.600000</td>\n      <td>0.333333</td>\n      <td>0.625000</td>\n      <td>0.384615</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 71 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = df_winrates.sample(frac=0.8, random_state=0)\n",
    "test_dataset = df_winrates.drop(train_dataset.index)\n",
    "train_dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "game_id\n3252704800    0\n4488699054    0\n3254899506    0\n6145685471    0\n1237727628    0\nName: label, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('label')\n",
    "test_labels = test_features.pop('label')\n",
    "train_labels.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(train_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm, width, depth, activation='relu'):\n",
    "    layer_l = [norm]\n",
    "    layer_l.extend([layers.Dense(width, activation=activation) for _ in range(depth)])\n",
    "    layer_l.append(layers.Dense(1, activation='softmax'))\n",
    "    model = keras.Sequential(layer_l)\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 70)               141       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4544      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,910\n",
      "Trainable params: 8,769\n",
      "Non-trainable params: 141\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model = build_and_compile_model(normalizer, 64, 2)\n",
    "dnn_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "367/367 [==============================] - 3s 5ms/step - loss: 0.5125 - val_loss: 0.4987\n",
      "Epoch 2/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4705 - val_loss: 0.4948\n",
      "Epoch 3/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4533 - val_loss: 0.4957\n",
      "Epoch 4/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4413 - val_loss: 0.4963\n",
      "Epoch 5/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4307 - val_loss: 0.4935\n",
      "Epoch 6/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4202 - val_loss: 0.5036\n",
      "Epoch 7/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4116 - val_loss: 0.5006\n",
      "Epoch 8/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4036 - val_loss: 0.5038\n",
      "Epoch 9/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.3952 - val_loss: 0.5050\n",
      "Epoch 10/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3883 - val_loss: 0.5018\n",
      "Epoch 11/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3816 - val_loss: 0.5141\n",
      "Epoch 12/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3740 - val_loss: 0.5080\n",
      "Epoch 13/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.3688 - val_loss: 0.5115\n",
      "Epoch 14/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.3622 - val_loss: 0.5154\n",
      "Epoch 15/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3565 - val_loss: 0.5158\n",
      "Epoch 16/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3479 - val_loss: 0.5143\n",
      "Epoch 17/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3477 - val_loss: 0.5197\n",
      "Epoch 18/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3418 - val_loss: 0.5217\n",
      "Epoch 19/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.3363 - val_loss: 0.5217\n",
      "Epoch 20/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3328 - val_loss: 0.5205\n",
      "Epoch 21/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3296 - val_loss: 0.5281\n",
      "Epoch 22/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.3245 - val_loss: 0.5189\n",
      "Epoch 23/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.3217 - val_loss: 0.5184\n",
      "Epoch 24/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3182 - val_loss: 0.5225\n",
      "Epoch 25/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3127 - val_loss: 0.5244\n",
      "Epoch 26/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.3140 - val_loss: 0.5318\n",
      "Epoch 27/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.3092 - val_loss: 0.5265\n",
      "Epoch 28/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.3079 - val_loss: 0.5273\n",
      "Epoch 29/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.3041 - val_loss: 0.5280\n",
      "Epoch 30/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.3006 - val_loss: 0.5344\n",
      "Epoch 31/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2998 - val_loss: 0.5368\n",
      "Epoch 32/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2980 - val_loss: 0.5297\n",
      "Epoch 33/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2932 - val_loss: 0.5326\n",
      "Epoch 34/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2934 - val_loss: 0.5310\n",
      "Epoch 35/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2918 - val_loss: 0.5353\n",
      "Epoch 36/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2892 - val_loss: 0.5319\n",
      "Epoch 37/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2873 - val_loss: 0.5432\n",
      "Epoch 38/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2852 - val_loss: 0.5347\n",
      "Epoch 39/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2848 - val_loss: 0.5376\n",
      "Epoch 40/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2811 - val_loss: 0.5412\n",
      "Epoch 41/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2794 - val_loss: 0.5430\n",
      "Epoch 42/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2804 - val_loss: 0.5415\n",
      "Epoch 43/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2759 - val_loss: 0.5448\n",
      "Epoch 44/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2775 - val_loss: 0.5431\n",
      "Epoch 45/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2763 - val_loss: 0.5415\n",
      "Epoch 46/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2723 - val_loss: 0.5409\n",
      "Epoch 47/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2705 - val_loss: 0.5486\n",
      "Epoch 48/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2682 - val_loss: 0.5424\n",
      "Epoch 49/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2695 - val_loss: 0.5423\n",
      "Epoch 50/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2648 - val_loss: 0.5511\n",
      "Epoch 51/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2682 - val_loss: 0.5448\n",
      "Epoch 52/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2662 - val_loss: 0.5451\n",
      "Epoch 53/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2633 - val_loss: 0.5442\n",
      "Epoch 54/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2633 - val_loss: 0.5479\n",
      "Epoch 55/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2602 - val_loss: 0.5496\n",
      "Epoch 56/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2598 - val_loss: 0.5482\n",
      "Epoch 57/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2586 - val_loss: 0.5455\n",
      "Epoch 58/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2577 - val_loss: 0.5481\n",
      "Epoch 59/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2573 - val_loss: 0.5522\n",
      "Epoch 60/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2554 - val_loss: 0.5493\n",
      "Epoch 61/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2547 - val_loss: 0.5543\n",
      "Epoch 62/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2544 - val_loss: 0.5511\n",
      "Epoch 63/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2525 - val_loss: 0.5496\n",
      "Epoch 64/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2507 - val_loss: 0.5482\n",
      "Epoch 65/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2516 - val_loss: 0.5584\n",
      "Epoch 66/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.2497 - val_loss: 0.5555\n",
      "Epoch 67/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.2505 - val_loss: 0.5562\n",
      "Epoch 68/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2482 - val_loss: 0.5555\n",
      "Epoch 69/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2462 - val_loss: 0.5597\n",
      "Epoch 70/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2439 - val_loss: 0.5566\n",
      "Epoch 71/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2463 - val_loss: 0.5596\n",
      "Epoch 72/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2437 - val_loss: 0.5619\n",
      "Epoch 73/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.2427 - val_loss: 0.5571\n",
      "Epoch 74/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.2419 - val_loss: 0.5633\n",
      "Epoch 75/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.2412 - val_loss: 0.5551\n",
      "Epoch 76/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.2430 - val_loss: 0.5613\n",
      "Epoch 77/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.2392 - val_loss: 0.5591\n",
      "Epoch 78/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.2387 - val_loss: 0.5563\n",
      "Epoch 79/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.2374 - val_loss: 0.5613\n",
      "Epoch 80/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.2372 - val_loss: 0.5618\n",
      "Epoch 81/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2374 - val_loss: 0.5585\n",
      "Epoch 82/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2379 - val_loss: 0.5625\n",
      "Epoch 83/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2335 - val_loss: 0.5624\n",
      "Epoch 84/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2342 - val_loss: 0.5756\n",
      "Epoch 85/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2341 - val_loss: 0.5650\n",
      "Epoch 86/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2316 - val_loss: 0.5633\n",
      "Epoch 87/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2330 - val_loss: 0.5661\n",
      "Epoch 88/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2334 - val_loss: 0.5654\n",
      "Epoch 89/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2310 - val_loss: 0.5647\n",
      "Epoch 90/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2307 - val_loss: 0.5664\n",
      "Epoch 91/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2312 - val_loss: 0.5676\n",
      "Epoch 92/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2291 - val_loss: 0.5688\n",
      "Epoch 93/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2305 - val_loss: 0.5649\n",
      "Epoch 94/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2282 - val_loss: 0.5672\n",
      "Epoch 95/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2296 - val_loss: 0.5666\n",
      "Epoch 96/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2280 - val_loss: 0.5707\n",
      "Epoch 97/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2270 - val_loss: 0.5672\n",
      "Epoch 98/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2251 - val_loss: 0.5715\n",
      "Epoch 99/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.2258 - val_loss: 0.5719\n",
      "Epoch 100/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.2259 - val_loss: 0.5694\n"
     ]
    }
   ],
   "source": [
    "history = dnn_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(patience=5, verbose=0, restore_best_weights=True)\n",
    "activations = ['relu', 'sigmoid', 'softmax', 'softplus', 'softsign', 'tanh', 'selu', 'elu', 'exponential']\n",
    "\n",
    "def test_model(width, depth, activation, verbose=1):\n",
    "    with tf.device(\"GPU:0\"):\n",
    "        model = build_and_compile_model(normalizer, width, depth, activation)\n",
    "        history_return = model.fit(\n",
    "            train_features,\n",
    "            train_labels,\n",
    "            validation_split=0.2,\n",
    "            verbose=verbose, epochs=100,\n",
    "            callbacks = [early_stop]\n",
    "        )\n",
    "    return min(history_return.history['val_loss']), len(history_return.history['val_loss'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.5056 - val_loss: 0.4953\n",
      "Epoch 2/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4716 - val_loss: 0.4845\n",
      "Epoch 3/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4546 - val_loss: 0.4914\n",
      "Epoch 4/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4439 - val_loss: 0.4936\n",
      "Epoch 5/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4326 - val_loss: 0.4941\n",
      "Epoch 6/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4229 - val_loss: 0.4920\n",
      "Epoch 7/100\n",
      "358/367 [============================>.] - ETA: 0s - loss: 0.4136Restoring model weights from the end of the best epoch: 2.\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4143 - val_loss: 0.4927\n",
      "Epoch 7: early stopping\n",
      "Epoch 1/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4866 - val_loss: 0.4851\n",
      "Epoch 2/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4773 - val_loss: 0.4812\n",
      "Epoch 3/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4749 - val_loss: 0.4815\n",
      "Epoch 4/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4753 - val_loss: 0.4805\n",
      "Epoch 5/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4721 - val_loss: 0.4902\n",
      "Epoch 6/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4722 - val_loss: 0.4745\n",
      "Epoch 7/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4696 - val_loss: 0.4752\n",
      "Epoch 8/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4699 - val_loss: 0.4741\n",
      "Epoch 9/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4675 - val_loss: 0.4858\n",
      "Epoch 10/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4656 - val_loss: 0.4717\n",
      "Epoch 11/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4628 - val_loss: 0.4708\n",
      "Epoch 12/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4610 - val_loss: 0.4689\n",
      "Epoch 13/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4581 - val_loss: 0.4683\n",
      "Epoch 14/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4552 - val_loss: 0.4656\n",
      "Epoch 15/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4519 - val_loss: 0.4648\n",
      "Epoch 16/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4517 - val_loss: 0.4635\n",
      "Epoch 17/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.4491 - val_loss: 0.4657\n",
      "Epoch 18/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4465 - val_loss: 0.4672\n",
      "Epoch 19/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4446 - val_loss: 0.4628\n",
      "Epoch 20/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4441 - val_loss: 0.4683\n",
      "Epoch 21/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.4422 - val_loss: 0.4650\n",
      "Epoch 22/100\n",
      "367/367 [==============================] - 1s 4ms/step - loss: 0.4386 - val_loss: 0.4640\n",
      "Epoch 23/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4355 - val_loss: 0.4642\n",
      "Epoch 24/100\n",
      "358/367 [============================>.] - ETA: 0s - loss: 0.4341Restoring model weights from the end of the best epoch: 19.\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.4342 - val_loss: 0.4721\n",
      "Epoch 24: early stopping\n",
      "Epoch 1/100\n",
      "367/367 [==============================] - 3s 6ms/step - loss: 0.5177 - val_loss: 0.5150\n",
      "Epoch 2/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.5118 - val_loss: 0.5086\n",
      "Epoch 3/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.5029 - val_loss: 0.4997\n",
      "Epoch 4/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4898 - val_loss: 0.4883\n",
      "Epoch 5/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4714 - val_loss: 0.4748\n",
      "Epoch 6/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4538 - val_loss: 0.4711\n",
      "Epoch 7/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4372 - val_loss: 0.4680\n",
      "Epoch 8/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4227 - val_loss: 0.4676\n",
      "Epoch 9/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4141 - val_loss: 0.4680\n",
      "Epoch 10/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4076 - val_loss: 0.4682\n",
      "Epoch 11/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4028 - val_loss: 0.4687\n",
      "Epoch 12/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3986 - val_loss: 0.4692\n",
      "Epoch 13/100\n",
      "359/367 [============================>.] - ETA: 0s - loss: 0.3953Restoring model weights from the end of the best epoch: 8.\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3945 - val_loss: 0.4699\n",
      "Epoch 13: early stopping\n",
      "Epoch 1/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4999 - val_loss: 0.4812\n",
      "Epoch 2/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4802 - val_loss: 0.4954\n",
      "Epoch 3/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4747 - val_loss: 0.4789\n",
      "Epoch 4/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4703 - val_loss: 0.4916\n",
      "Epoch 5/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4661 - val_loss: 0.4912\n",
      "Epoch 6/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4655 - val_loss: 0.4791\n",
      "Epoch 7/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4609 - val_loss: 0.4978\n",
      "Epoch 8/100\n",
      "357/367 [============================>.] - ETA: 0s - loss: 0.4600Restoring model weights from the end of the best epoch: 3.\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4598 - val_loss: 0.4810\n",
      "Epoch 8: early stopping\n",
      "Epoch 1/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4988 - val_loss: 0.4817\n",
      "Epoch 2/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4716 - val_loss: 0.4813\n",
      "Epoch 3/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4661 - val_loss: 0.4805\n",
      "Epoch 4/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4571 - val_loss: 0.4781\n",
      "Epoch 5/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4511 - val_loss: 0.4830\n",
      "Epoch 6/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4436 - val_loss: 0.4855\n",
      "Epoch 7/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4356 - val_loss: 0.4878\n",
      "Epoch 8/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4290 - val_loss: 0.4872\n",
      "Epoch 9/100\n",
      "359/367 [============================>.] - ETA: 0s - loss: 0.4211Restoring model weights from the end of the best epoch: 4.\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4209 - val_loss: 0.4921\n",
      "Epoch 9: early stopping\n",
      "Epoch 1/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.5059 - val_loss: 0.4838\n",
      "Epoch 2/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4780 - val_loss: 0.4861\n",
      "Epoch 3/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4653 - val_loss: 0.4889\n",
      "Epoch 4/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4587 - val_loss: 0.4876\n",
      "Epoch 5/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4470 - val_loss: 0.4917\n",
      "Epoch 6/100\n",
      "356/367 [============================>.] - ETA: 0s - loss: 0.4403Restoring model weights from the end of the best epoch: 1.\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4404 - val_loss: 0.4925\n",
      "Epoch 6: early stopping\n",
      "Epoch 1/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.5385 - val_loss: 0.5102\n",
      "Epoch 2/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4888 - val_loss: 0.4963\n",
      "Epoch 3/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4788 - val_loss: 0.4973\n",
      "Epoch 4/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4713 - val_loss: 0.4892\n",
      "Epoch 5/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4620 - val_loss: 0.4914\n",
      "Epoch 6/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4595 - val_loss: 0.4886\n",
      "Epoch 7/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4543 - val_loss: 0.4830\n",
      "Epoch 8/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4501 - val_loss: 0.4919\n",
      "Epoch 9/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4482 - val_loss: 0.4925\n",
      "Epoch 10/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4433 - val_loss: 0.4952\n",
      "Epoch 11/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4390 - val_loss: 0.4904\n",
      "Epoch 12/100\n",
      "356/367 [============================>.] - ETA: 0s - loss: 0.4370Restoring model weights from the end of the best epoch: 7.\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4370 - val_loss: 0.4927\n",
      "Epoch 12: early stopping\n",
      "Epoch 1/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.5080 - val_loss: 0.4936\n",
      "Epoch 2/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4819 - val_loss: 0.4862\n",
      "Epoch 3/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: 0.4746 - val_loss: 0.4881\n",
      "Epoch 4/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4680 - val_loss: 0.4838\n",
      "Epoch 5/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4608 - val_loss: 0.4853\n",
      "Epoch 6/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4567 - val_loss: 0.4966\n",
      "Epoch 7/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4527 - val_loss: 0.4900\n",
      "Epoch 8/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4465 - val_loss: 0.4849\n",
      "Epoch 9/100\n",
      "362/367 [============================>.] - ETA: 0s - loss: 0.4439Restoring model weights from the end of the best epoch: 4.\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4441 - val_loss: 0.4887\n",
      "Epoch 9: early stopping\n",
      "Epoch 1/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "367/367 [==============================] - 2s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "364/367 [============================>.] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 1.\n",
      "367/367 [==============================] - 2s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('relu', 0.4844696521759033),\n ('sigmoid', 0.4628167152404785),\n ('softmax', 0.4676401615142822),\n ('softplus', 0.47889775037765503),\n ('softsign', 0.4780551791191101),\n ('tanh', 0.4837893843650818),\n ('selu', 0.48302292823791504),\n ('elu', 0.48381277918815613),\n ('exponential', nan)]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(act, test_model(64, 2, act, 0)) for act in activations]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "[((18, 1, 'softmax'), (0.4686773419380188, 27)),\n ((18, 2, 'softmax'), (0.46939608454704285, 13)),\n ((18, 4, 'softmax'), (0.4693832993507385, 15)),\n ((72, 1, 'softmax'), (0.4719468653202057, 11)),\n ((72, 2, 'softmax'), (0.4623214304447174, 16)),\n ((72, 4, 'softmax'), (0.48021045327186584, 12)),\n ((144, 1, 'softmax'), (0.46452662348747253, 13)),\n ((144, 2, 'softmax'), (0.46166375279426575, 18)),\n ((144, 4, 'softmax'), (0.48021358251571655, 16))]"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes = []\n",
    "for x in [18, 72, 144]:\n",
    "    for y in [1, 2, 4]:\n",
    "        for z in ['softmax']:\n",
    "            modes.append((x, y, z))\n",
    "results = [(mode, test_model(mode[0], mode[1], mode[2], 0)) for mode in modes]\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "[((144, 2, 'softmax'), (0.46166375279426575, 18)),\n ((72, 2, 'softmax'), (0.4623214304447174, 16)),\n ((144, 1, 'softmax'), (0.46452662348747253, 13)),\n ((18, 1, 'softmax'), (0.4686773419380188, 27)),\n ((18, 4, 'softmax'), (0.4693832993507385, 15)),\n ((18, 2, 'softmax'), (0.46939608454704285, 13)),\n ((72, 1, 'softmax'), (0.4719468653202057, 11)),\n ((72, 4, 'softmax'), (0.48021045327186584, 12)),\n ((144, 4, 'softmax'), (0.48021358251571655, 16))]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key=lambda x: x[1][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "367/367 [==============================] - 3s 6ms/step - loss: 0.5172 - val_loss: 0.5144\n",
      "Epoch 2/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.5116 - val_loss: 0.5079\n",
      "Epoch 3/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.5044 - val_loss: 0.5011\n",
      "Epoch 4/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4942 - val_loss: 0.4913\n",
      "Epoch 5/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4775 - val_loss: 0.4769\n",
      "Epoch 6/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4585 - val_loss: 0.4724\n",
      "Epoch 7/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4395 - val_loss: 0.4677\n",
      "Epoch 8/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4149 - val_loss: 0.4666\n",
      "Epoch 9/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.4014 - val_loss: 0.4666\n",
      "Epoch 10/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3920 - val_loss: 0.4671\n",
      "Epoch 11/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3849 - val_loss: 0.4675\n",
      "Epoch 12/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.3782 - val_loss: 0.4676\n",
      "Epoch 13/100\n",
      "367/367 [==============================] - 2s 6ms/step - loss: 0.3721 - val_loss: 0.4692\n",
      "Epoch 14/100\n",
      "367/367 [==============================] - 2s 5ms/step - loss: 0.3664 - val_loss: 0.4691\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.4666041433811188, 14)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(288, 2, 'softmax')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}